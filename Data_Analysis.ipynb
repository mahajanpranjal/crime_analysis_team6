{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "106e6eb7-a721-4a3a-81e3-8885bcab4c51",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"#row_number#\":55},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763604028709}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your paths\n",
    "catalog = \"workspace\"\n",
    "schema  = \"crime\"\n",
    "volume = \"datastore\"\n",
    "download_url = \"https://data.lacity.org/resource/2nrs-mtv8.csv?$limit=10000000\"  # Added limit parameter\n",
    "file_name = \"crime_data.csv\"\n",
    "table_name = \"crime_bronze\"\n",
    "path_volume = \"/Volumes/\" + catalog + \"/\" + schema + \"/\" + volume\n",
    "path_table = catalog + \".\" + schema \n",
    "\n",
    "print(f\"Volume path: {path_volume}\")\n",
    "print(f\"Table path: {path_table}\")\n",
    "\n",
    "# Full file path in the volume\n",
    "file_path = f\"{path_volume}/{file_name}\"\n",
    "print(f\"File will be saved to: {file_path}\")\n",
    "\n",
    "# Step 1: Download the data with pandas (handles query params better)\n",
    "print(\"Downloading data from LA City portal...\")\n",
    "df_pandas = pd.read_csv(download_url)\n",
    "print(f\"Downloaded {len(df_pandas):,} rows\")\n",
    "\n",
    "# Step 2: Save to Unity Catalog volume\n",
    "print(f\"Saving to {file_path}...\")\n",
    "df_pandas.to_csv(f\"/Volumes/{catalog}/{schema}/{volume}/{file_name}\", index=False)\n",
    "print(\"File saved successfully!\")\n",
    "\n",
    "# Step 3: Read into Spark DataFrame\n",
    "print(\"Reading into Spark DataFrame...\")\n",
    "df_spark = spark.read.csv(\n",
    "    file_path,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Success!\")\n",
    "print(f\"   Rows: {df_spark.count():,}\")\n",
    "print(f\"   File: {file_path}\")\n",
    "\n",
    "# Display sample\n",
    "display(df_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "785a3512-2060-466b-851c-9d611b802645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f69edec-a6a8-46e4-a25a-dfc5b9ca17c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the bronze table\n",
    "catalog = \"workspace\"\n",
    "schema = \"crime\"\n",
    "table_name = \"crime_bronze\"\n",
    "\n",
    "df = spark.table(f\"{catalog}.{schema}.{table_name}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: BASIC DATA INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal Rows: {df.count():,}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc0a9054-fe17-492f-9279-cc483c1d1812",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "catalog = \"workspace\"\n",
    "schema = \"crime\"\n",
    "volume = \"datastore\"\n",
    "table_name = \"crime_bronze\"\n",
    "\n",
    "# Load bronze data\n",
    "df = spark.table(f\"{catalog}.{schema}.{table_name}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: DATA PROFILING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Basic statistics\n",
    "total_rows = df.count()\n",
    "total_cols = len(df.columns)\n",
    "\n",
    "print(f\"\\n1.1 DATASET OVERVIEW\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total Records: {total_rows:,}\")\n",
    "print(f\"Total Columns: {total_cols}\")\n",
    "\n",
    "# Check duplicates\n",
    "duplicate_cases = df.groupBy('DR_NO').count().filter(col('count') > 1).count()\n",
    "print(f\"Duplicate Case Numbers: {duplicate_cases:,}\")\n",
    "\n",
    "# Display schema\n",
    "print(f\"\\n1.2 DATA TYPES\")\n",
    "print(f\"{'='*80}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b238049-d71b-4703-9876-79556dd2707b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.3 NULL VALUE ANALYSIS\")\n",
    "print(f\"{'='*80}\")\n",
    "# Calculate nulls for all columns\n",
    "null_analysis = []\n",
    "for column_name in df.columns:\n",
    "    null_count = df.filter(col(column_name).isNull()).count()\n",
    "    null_pct = (null_count / total_rows) * 100\n",
    "    null_analysis.append({\n",
    "        'Column': column_name,\n",
    "        'Null_Count': null_count,\n",
    "        'Null_Percentage': float(f\"{null_pct:.2f}\")  # Format instead of round\n",
    "    })\n",
    "null_df = pd.DataFrame(null_analysis).sort_values('Null_Percentage', ascending=False)\n",
    "print(null_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e05faa5f-7b88-4975-bd55-734489b8e3f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is a data quality audit to identify problems in the date fields before analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40299b1-562d-4379-b605-810a29c956e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.5 DATE QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Convert dates\n",
    "df_dates = df.withColumn('date_reported', to_date(col('date_rptd'))) \\\n",
    "             .withColumn('date_occurred', to_date(col('date_occ')))\n",
    "\n",
    "# Future dates\n",
    "future_reported = df_dates.filter(col('date_reported') > current_date()).count()\n",
    "future_occurred = df_dates.filter(col('date_occurred') > current_date()).count()\n",
    "\n",
    "# Illogical dates (occurrence after report)\n",
    "occ_after_report = df_dates.filter(col('date_occurred') > col('date_reported')).count()\n",
    "\n",
    "# Null dates\n",
    "null_reported = df.filter(col('date_rptd').isNull()).count()\n",
    "null_occurred = df.filter(col('date_occ').isNull()).count()\n",
    "\n",
    "print(f\"Date Issues:\")\n",
    "print(f\"  Null Report Dates:           {null_reported:,}\")\n",
    "print(f\"  Null Occurrence Dates:       {null_occurred:,}\")\n",
    "print(f\"  Future Report Dates:         {future_reported:,}\")\n",
    "print(f\"  Future Occurrence Dates:     {future_occurred:,}\")\n",
    "print(f\"  Occurrence > Report Date:    {occ_after_report:,}\")\n",
    "\n",
    "# Date ranges\n",
    "date_stats = df_dates.select(\n",
    "    min('date_occurred').alias('min_date'),\n",
    "    max('date_occurred').alias('max_date')\n",
    ").collect()[0]\n",
    "print(f\"\\nDate Range: {date_stats['min_date']} to {date_stats['max_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8754628f-fc23-4877-9730-20e0515fc01a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This helps identify data entry errors where times were recorded incorrectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77402952-8c19-4b71-b575-69958d6ec80d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.6 TIME QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Time statistics\n",
    "null_time = df.filter(col('time_occ').isNull()).count()\n",
    "invalid_time = df.filter((col('time_occ') < 0) | (col('time_occ') > 2359)).count()\n",
    "\n",
    "print(f\"Time Issues:\")\n",
    "print(f\"  Null Times:                  {null_time:,}\")\n",
    "print(f\"  Invalid Times (<0 or >2359): {invalid_time:,}\")\n",
    "\n",
    "# Time range\n",
    "time_stats = df.select(min('time_occ'), max('time_occ')).collect()[0]\n",
    "print(f\"\\nTime Range: {time_stats[0]} to {time_stats[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c4a5678-50ca-436c-b018-be709ef0a5d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.7 COORDINATE QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Coordinate issues\n",
    "null_lat = df.filter(col('lat').isNull()).count()\n",
    "null_lon = df.filter(col('lon').isNull()).count()\n",
    "zero_lat = df.filter(col('lat') == 0).count()\n",
    "zero_lon = df.filter(col('lon') == 0).count()\n",
    "both_zero = df.filter((col('lat') == 0) & (col('lon') == 0)).count()\n",
    "both_null = df.filter(col('lat').isNull() & col('lon').isNull()).count()\n",
    "\n",
    "# Valid coordinates\n",
    "valid_coords = df.filter(\n",
    "    (col('lat').isNotNull()) & (col('lon').isNotNull()) &\n",
    "    (col('lat') != 0) & (col('lon') != 0)\n",
    ").count()\n",
    "\n",
    "# LA bounds check (Lat: 33.7-34.8, Lon: -118.7 to -118.0)\n",
    "outside_la = df.filter(\n",
    "    (col('lat').isNotNull()) & (col('lon').isNotNull()) &\n",
    "    (col('lat') != 0) & (col('lon') != 0) &\n",
    "    ((col('lat') < 33.7) | (col('lat') > 34.8) |\n",
    "     (col('lon') < -118.7) | (col('lon') > -118.0))\n",
    ").count()\n",
    "\n",
    "print(f\"Coordinate Issues:\")\n",
    "print(f\"  Null Latitude:         {null_lat:,} ({null_lat/total_rows*100:.2f}%)\")\n",
    "print(f\"  Null Longitude:        {null_lon:,} ({null_lon/total_rows*100:.2f}%)\")\n",
    "print(f\"  Zero Latitude:         {zero_lat:,} ({zero_lat/total_rows*100:.2f}%)\")\n",
    "print(f\"  Zero Longitude:        {zero_lon:,} ({zero_lon/total_rows*100:.2f}%)\")\n",
    "print(f\"  Both Null:             {both_null:,} ({both_null/total_rows*100:.2f}%)\")\n",
    "print(f\"  Both Zero:             {both_zero:,} ({both_zero/total_rows*100:.2f}%)\")\n",
    "print(f\"  Outside LA Bounds:     {outside_la:,} ({outside_la/total_rows*100:.2f}%)\")\n",
    "print(f\"  Valid Coordinates:     {valid_coords:,} ({valid_coords/total_rows*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d08008d-9cbf-4b11-a01c-108586efd33f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.8 AGE QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Age issues\n",
    "null_age = df.filter(col('vict_age').isNull()).count()\n",
    "negative_age = df.filter(col('vict_age') < 0).count()\n",
    "zero_age = df.filter(col('vict_age') == 0).count()\n",
    "over_120 = df.filter(col('vict_age') > 120).count()\n",
    "valid_age = df.filter((col('vict_age') >= 1) & (col('vict_age') <= 120)).count()\n",
    "\n",
    "print(f\"Age Issues:\")\n",
    "print(f\"  Null Ages:             {null_age:,} ({null_age/total_rows*100:.2f}%)\")\n",
    "print(f\"  Negative Ages:         {negative_age:,} ({negative_age/total_rows*100:.2f}%)\")\n",
    "print(f\"  Zero Ages:             {zero_age:,} ({zero_age/total_rows*100:.2f}%)\")\n",
    "print(f\"  Ages > 120:            {over_120:,} ({over_120/total_rows*100:.2f}%)\")\n",
    "print(f\"  Valid Ages (1-120):    {valid_age:,} ({valid_age/total_rows*100:.2f}%)\")\n",
    "\n",
    "# Age statistics\n",
    "age_stats = df.filter((col('vict_age') >= 0) & (col('vict_age') <= 120)).select(\n",
    "    min('vict_age').alias('min'),\n",
    "    max('vict_age').alias('max'),\n",
    "    avg('vict_age').alias('mean')\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nValid Age Statistics:\")\n",
    "print(f\"  Min:  {age_stats['min']}\")\n",
    "print(f\"  Max:  {age_stats['max']}\")\n",
    "print(f\"  Mean: {age_stats['mean']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3af1949d-6f8e-460d-be50-99496e385f57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from workspace.crime.crime_bronze where vict_age < 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92895178-181c-4355-a1d3-78e3c4418488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6766247071519530,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
