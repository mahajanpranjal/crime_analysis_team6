{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03955e0e-474e-435e-868a-6dacce141786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Your paths\n",
    "catalog = \"workspace\"\n",
    "schema  = \"crime\"\n",
    "volume = \"datastore\"\n",
    "download_url = \"https://data.lacity.org/resource/2nrs-mtv8.csv?$limit=10000000\"  # Added limit parameter\n",
    "file_name = \"crime_data.csv\"\n",
    "table_name = \"crime_bronze\"\n",
    "path_volume = \"/Volumes/\" + catalog + \"/\" + schema + \"/\" + volume\n",
    "path_table = catalog + \".\" + schema \n",
    "\n",
    "print(f\"Volume path: {path_volume}\")\n",
    "print(f\"Table path: {path_table}\")\n",
    "\n",
    "# Full file path in the volume\n",
    "file_path = f\"{path_volume}/{file_name}\"\n",
    "print(f\"File will be saved to: {file_path}\")\n",
    "\n",
    "# Step 1: Download the data with pandas (handles query params better)\n",
    "print(\"Downloading data from LA City portal...\")\n",
    "df_pandas = pd.read_csv(download_url)\n",
    "print(f\"Downloaded {len(df_pandas):,} rows\")\n",
    "\n",
    "# Step 2: Save to Unity Catalog volume\n",
    "print(f\"Saving to {file_path}...\")\n",
    "df_pandas.to_csv(f\"/Volumes/{catalog}/{schema}/{volume}/{file_name}\", index=False)\n",
    "print(\"File saved successfully!\")\n",
    "\n",
    "# Step 3: Read into Spark DataFrame\n",
    "print(\"Reading into Spark DataFrame...\")\n",
    "df_spark = spark.read.csv(\n",
    "    file_path,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Success!\")\n",
    "print(f\"   Rows: {df_spark.count():,}\")\n",
    "print(f\"   File: {file_path}\")\n",
    "\n",
    "# Display sample\n",
    "display(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c216c35-1ff5-4904-9f00-5c585c8a1b0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the bronze table\n",
    "catalog = \"workspace\"\n",
    "schema = \"crime\"\n",
    "table_name = \"crime_bronze\"\n",
    "\n",
    "df = spark.table(f\"{catalog}.{schema}.{table_name}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: BASIC DATA INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal Rows: {df.count():,}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn Names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02562d6b-653d-4a24-8394-480d9a1f9671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "catalog = \"workspace\"\n",
    "schema = \"crime\"\n",
    "volume = \"datastore\"\n",
    "table_name = \"crime_bronze\"\n",
    "\n",
    "# Load bronze data\n",
    "df = spark.table(f\"{catalog}.{schema}.{table_name}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: DATA PROFILING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Basic statistics\n",
    "total_rows = df.count()\n",
    "total_cols = len(df.columns)\n",
    "\n",
    "print(f\"\\n1.1 DATASET OVERVIEW\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total Records: {total_rows:,}\")\n",
    "print(f\"Total Columns: {total_cols}\")\n",
    "\n",
    "# Check duplicates\n",
    "duplicate_cases = df.groupBy('DR_NO').count().filter(col('count') > 1).count()\n",
    "print(f\"Duplicate Case Numbers: {duplicate_cases:,}\")\n",
    "\n",
    "# Display schema\n",
    "print(f\"\\n1.2 DATA TYPES\")\n",
    "print(f\"{'='*80}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "163a1d13-8a2a-472c-8b41-edecbd970090",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.3 NULL VALUE ANALYSIS\")\n",
    "print(f\"{'='*80}\")\n",
    "# Calculate nulls for all columns\n",
    "null_analysis = []\n",
    "for column_name in df.columns:\n",
    "    null_count = df.filter(col(column_name).isNull()).count()\n",
    "    null_pct = (null_count / total_rows) * 100\n",
    "    null_analysis.append({\n",
    "        'Column': column_name,\n",
    "        'Null_Count': null_count,\n",
    "        'Null_Percentage': float(f\"{null_pct:.2f}\")  # Format instead of round\n",
    "    })\n",
    "null_df = pd.DataFrame(null_analysis).sort_values('Null_Percentage', ascending=False)\n",
    "print(null_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9cf24d7-3a31-4f1d-ae45-982aab623269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.5 DATE QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Convert dates\n",
    "df_dates = df.withColumn('date_reported', to_date(col('date_rptd'))) \\\n",
    "             .withColumn('date_occurred', to_date(col('date_occ')))\n",
    "\n",
    "# Future dates\n",
    "future_reported = df_dates.filter(col('date_reported') > current_date()).count()\n",
    "future_occurred = df_dates.filter(col('date_occurred') > current_date()).count()\n",
    "\n",
    "# Illogical dates (occurrence after report)\n",
    "occ_after_report = df_dates.filter(col('date_occurred') > col('date_reported')).count()\n",
    "\n",
    "# Null dates\n",
    "null_reported = df.filter(col('date_rptd').isNull()).count()\n",
    "null_occurred = df.filter(col('date_occ').isNull()).count()\n",
    "\n",
    "print(f\"Date Issues:\")\n",
    "print(f\"  Null Report Dates:           {null_reported:,}\")\n",
    "print(f\"  Null Occurrence Dates:       {null_occurred:,}\")\n",
    "print(f\"  Future Report Dates:         {future_reported:,}\")\n",
    "print(f\"  Future Occurrence Dates:     {future_occurred:,}\")\n",
    "print(f\"  Occurrence > Report Date:    {occ_after_report:,}\")\n",
    "\n",
    "# Date ranges\n",
    "date_stats = df_dates.select(\n",
    "    min('date_occurred').alias('min_date'),\n",
    "    max('date_occurred').alias('max_date')\n",
    ").collect()[0]\n",
    "print(f\"\\nDate Range: {date_stats['min_date']} to {date_stats['max_date']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed4bd046-bcf9-4ea6-8499-b1a6263576a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.6 TIME QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Time statistics\n",
    "null_time = df.filter(col('time_occ').isNull()).count()\n",
    "invalid_time = df.filter((col('time_occ') < 0) | (col('time_occ') > 2359)).count()\n",
    "\n",
    "print(f\"Time Issues:\")\n",
    "print(f\"  Null Times:                  {null_time:,}\")\n",
    "print(f\"  Invalid Times (<0 or >2359): {invalid_time:,}\")\n",
    "\n",
    "# Time range\n",
    "time_stats = df.select(min('time_occ'), max('time_occ')).collect()[0]\n",
    "print(f\"\\nTime Range: {time_stats[0]} to {time_stats[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5d39804-d111-4440-803a-e1bfeca079b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.7 COORDINATE QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Coordinate issues\n",
    "null_lat = df.filter(col('lat').isNull()).count()\n",
    "null_lon = df.filter(col('lon').isNull()).count()\n",
    "zero_lat = df.filter(col('lat') == 0).count()\n",
    "zero_lon = df.filter(col('lon') == 0).count()\n",
    "both_zero = df.filter((col('lat') == 0) & (col('lon') == 0)).count()\n",
    "both_null = df.filter(col('lat').isNull() & col('lon').isNull()).count()\n",
    "\n",
    "# Valid coordinates\n",
    "valid_coords = df.filter(\n",
    "    (col('lat').isNotNull()) & (col('lon').isNotNull()) &\n",
    "    (col('lat') != 0) & (col('lon') != 0)\n",
    ").count()\n",
    "\n",
    "# LA bounds check (Lat: 33.7-34.8, Lon: -118.7 to -118.0)\n",
    "outside_la = df.filter(\n",
    "    (col('lat').isNotNull()) & (col('lon').isNotNull()) &\n",
    "    (col('lat') != 0) & (col('lon') != 0) &\n",
    "    ((col('lat') < 33.7) | (col('lat') > 34.8) |\n",
    "     (col('lon') < -118.7) | (col('lon') > -118.0))\n",
    ").count()\n",
    "\n",
    "print(f\"Coordinate Issues:\")\n",
    "print(f\"  Null Latitude:         {null_lat:,} ({null_lat/total_rows*100:.2f}%)\")\n",
    "print(f\"  Null Longitude:        {null_lon:,} ({null_lon/total_rows*100:.2f}%)\")\n",
    "print(f\"  Zero Latitude:         {zero_lat:,} ({zero_lat/total_rows*100:.2f}%)\")\n",
    "print(f\"  Zero Longitude:        {zero_lon:,} ({zero_lon/total_rows*100:.2f}%)\")\n",
    "print(f\"  Both Null:             {both_null:,} ({both_null/total_rows*100:.2f}%)\")\n",
    "print(f\"  Both Zero:             {both_zero:,} ({both_zero/total_rows*100:.2f}%)\")\n",
    "print(f\"  Outside LA Bounds:     {outside_la:,} ({outside_la/total_rows*100:.2f}%)\")\n",
    "print(f\"  Valid Coordinates:     {valid_coords:,} ({valid_coords/total_rows*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "266a2153-ab7c-4d55-bf88-ce5e5fec0354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\n1.8 AGE QUALITY ISSUES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Age issues\n",
    "null_age = df.filter(col('vict_age').isNull()).count()\n",
    "negative_age = df.filter(col('vict_age') < 0).count()\n",
    "zero_age = df.filter(col('vict_age') == 0).count()\n",
    "over_120 = df.filter(col('vict_age') > 120).count()\n",
    "valid_age = df.filter((col('vict_age') >= 1) & (col('vict_age') <= 120)).count()\n",
    "\n",
    "print(f\"Age Issues:\")\n",
    "print(f\"  Null Ages:             {null_age:,} ({null_age/total_rows*100:.2f}%)\")\n",
    "print(f\"  Negative Ages:         {negative_age:,} ({negative_age/total_rows*100:.2f}%)\")\n",
    "print(f\"  Zero Ages:             {zero_age:,} ({zero_age/total_rows*100:.2f}%)\")\n",
    "print(f\"  Ages > 120:            {over_120:,} ({over_120/total_rows*100:.2f}%)\")\n",
    "print(f\"  Valid Ages (1-120):    {valid_age:,} ({valid_age/total_rows*100:.2f}%)\")\n",
    "\n",
    "# Age statistics\n",
    "age_stats = df.filter((col('vict_age') >= 0) & (col('vict_age') <= 120)).select(\n",
    "    min('vict_age').alias('min'),\n",
    "    max('vict_age').alias('max'),\n",
    "    avg('vict_age').alias('mean')\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nValid Age Statistics:\")\n",
    "print(f\"  Min:  {age_stats['min']}\")\n",
    "print(f\"  Max:  {age_stats['max']}\")\n",
    "print(f\"  Mean: {age_stats['mean']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad903b02-5cf5-4eb1-9ebd-42391f17ae12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from workspace.crime.crime_bronze where vict_age < 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851850dd-a46b-4b26-a04d-5b72c43a6ec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Check dimension counts\n",
    "SELECT 'dim_date' as table_name, COUNT(*) as row_count FROM workspace.crime.dim_date\n",
    "UNION ALL\n",
    "SELECT 'dim_time', COUNT(*) FROM workspace.crime.dim_time\n",
    "UNION ALL\n",
    "SELECT 'dim_location', COUNT(*) FROM workspace.crime.dim_location_gold\n",
    "UNION ALL\n",
    "SELECT 'dim_crime_type', COUNT(*) FROM workspace.crime.dim_crime_type\n",
    "UNION ALL\n",
    "SELECT 'dim_weapon', COUNT(*) FROM workspace.crime.dim_weapon\n",
    "UNION ALL\n",
    "SELECT 'dim_victim', COUNT(*) FROM workspace.crime.dim_victim\n",
    "UNION ALL\n",
    "SELECT 'dim_status', COUNT(*) FROM workspace.crime.dim_status\n",
    "UNION ALL\n",
    "SELECT 'fact_crime', COUNT(*) FROM workspace.crime.fact_crime;\n",
    "\n",
    "-- Verify fact table has all keys populated\n",
    "SELECT \n",
    "    COUNT(*) as total_rows,\n",
    "    COUNT(date_key) as has_date_key,\n",
    "    COUNT(time_key) as has_time_key,\n",
    "    COUNT(location_key) as has_location_key,\n",
    "    COUNT(crime_type_key) as has_crime_type_key,\n",
    "    COUNT(weapon_key) as has_weapon_key,\n",
    "    COUNT(victim_key) as has_victim_key,\n",
    "    COUNT(status_key) as has_status_key\n",
    "FROM workspace.crime.fact_crime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3242a525-ac84-4df5-9a95-15e13a8ce821",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"#row_number#\":25},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763935620577}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "    COUNT(descent) as has_descent,\n",
    "    COUNT(rpt_dist_no) as has_rpt_dist,\n",
    "    SUM(CASE WHEN is_arrest_flag = TRUE THEN 1 ELSE 0 END) as total_arrests,\n",
    "    SUM(CASE WHEN is_arrest_flag = FALSE THEN 1 ELSE 0 END) as no_arrests\n",
    "FROM workspace.crime.fact_crime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bbd7de6-5be6-45b8-a75c-fb5d517536d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from workspace.crime.dim_date;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe44f79a-4112-4857-8e6b-0babbc74b3a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from workspace.crime.dim_victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed94a0b2-6955-4649-9dfd-78a3d3b046ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "    v.age_group,\n",
    "    CASE \n",
    "        WHEN v.age_group = '0-17' THEN 'Juvenile'\n",
    "        WHEN v.age_group = 'Unknown' THEN 'Unknown'\n",
    "        ELSE 'Adult'\n",
    "    END AS arrest_type,\n",
    "    COUNT(DISTINCT f.crime_incident_key) AS arrest_count\n",
    "FROM workspace.crime.fact_crime f\n",
    "JOIN workspace.crime.dim_victim v ON f.victim_key = v.victim_key\n",
    "WHERE f.is_arrest_flag = TRUE\n",
    "GROUP BY v.age_group, arrest_type\n",
    "ORDER BY arrest_count DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e702cfa-3831-420c-bfe2-5e768c5edd61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT crime_incident_key) \n",
    "FROM workspace.crime.fact_crime\n",
    "WHERE is_arrest_flag = TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dbe8ddb-eb03-4422-8cfd-2658ea804db2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT COUNT(DISTINCT crime_incident_key) AS total_arrests\n",
    "FROM workspace.crime.fact_crime\n",
    "WHERE is_arrest_flag = TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c590706-944e-4ed9-84f6-43f994f0cbf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "    d.year,\n",
    "    d.month,\n",
    "    d.month_name,\n",
    "    COUNT(DISTINCT f.crime_incident_key) AS crime_count\n",
    "FROM workspace.crime.fact_crime f\n",
    "JOIN workspace.crime.dim_date d ON f.date_key = d.date_key\n",
    "WHERE d.year = 2025\n",
    "GROUP BY d.year, d.month, d.month_name\n",
    "ORDER BY d.month;\n",
    "\n",
    "\n",
    "SELECT \n",
    "    COUNT(DISTINCT f.crime_incident_key) AS total_crimes_2025\n",
    "FROM workspace.crime.fact_crime f\n",
    "JOIN workspace.crime.dim_date d ON f.date_key = d.date_key\n",
    "WHERE d.year = 2025;\n",
    "\n",
    "\n",
    "\n",
    "SELECT \n",
    "    d.year,\n",
    "    COUNT(DISTINCT f.crime_incident_key) AS crime_count\n",
    "FROM workspace.crime.fact_crime f\n",
    "JOIN workspace.crime.dim_date d ON f.date_key = d.date_key\n",
    "GROUP BY d.year\n",
    "ORDER BY d.year; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e804dcaf-343a-422c-bc87-a3a27d131b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select Count(DISTINCT f.crime_incident_key) as total_crimes_2025 from workspace.crime.fact_crime f"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5750257199388620,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Profile_Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
