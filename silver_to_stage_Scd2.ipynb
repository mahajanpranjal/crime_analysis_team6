{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85382d42-b0b0-4641-8d25-ec0978946a7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Notebook: apply_scd2_location.py\n",
    "\n",
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# ============================================================================\n",
    "# EXTRACT LOCATION DATA FROM SILVER\n",
    "# ============================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"location_source\",\n",
    "    comment=\"Location data for SCD Type 2\"\n",
    ")\n",
    "def location_source():\n",
    "    df = dlt.read(\"crime_silver\")\n",
    "    \n",
    "    # Extract unique location records\n",
    "    location_df = df.select(\n",
    "        col(\"area\"),\n",
    "        col(\"area_name\"),\n",
    "        col(\"lat_clean\"),\n",
    "        col(\"lon_clean\"),\n",
    "        col(\"processing_timestamp\")\n",
    "    ).distinct().filter(col(\"area\").isNotNull())\n",
    "    \n",
    "    return location_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c40722a0-8d2e-4e12-8f18-a477c0e049c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dlt.create_streaming_table(\n",
    "    name=\"dim_location_scd2_raw\",\n",
    "    comment=\"SCD Type 2 tracking for location\"\n",
    ")\n",
    "\n",
    "dlt.apply_changes(\n",
    "    target=\"dim_location_scd2_raw\",\n",
    "    source=\"location_source\",\n",
    "    keys=[\"area\"],\n",
    "    sequence_by=\"processing_timestamp\",\n",
    "    ignore_null_updates=True,\n",
    "    stored_as_scd_type=2  # ‚Üê SCD Type 2 happens HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e7262b6-59a5-45db-8903-ab8de5a871fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CLEAN SCD TYPE 2 OUTPUT - READY FOR SNOWFLAKE\n",
    "# ============================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"dim_location_gold\",\n",
    "    comment=\"Location dimension with SCD Type 2 - READY FOR SNOWFLAKE\"\n",
    ")\n",
    "def dim_location_gold():\n",
    "    \"\"\"\n",
    "    This table has SCD Type 2 ALREADY APPLIED\n",
    "    Just load this to Snowflake - no more SCD logic needed!\n",
    "    \"\"\"\n",
    "    df = spark.read.table(\"workspace.crime.dim_location_scd2_raw\")\n",
    "    \n",
    "    # Extract SCD Type 2 metadata from DLT columns\n",
    "    df = df.withColumn(\"effective_date\", \n",
    "                       to_date(col(\"__START_AT\")))\n",
    "    df = df.withColumn(\"end_date\", \n",
    "                       to_date(col(\"__END_AT\")))\n",
    "    df = df.withColumn(\"is_current\", \n",
    "                       when(col(\"end_date\").isNull(), True).otherwise(False))\n",
    "    \n",
    "    # Generate surrogate key with version\n",
    "    from pyspark.sql.window import Window\n",
    "    window_spec = Window.partitionBy(\"area\").orderBy(\"effective_date\")\n",
    "    df = df.withColumn(\"version_num\", row_number().over(window_spec))\n",
    "    df = df.withColumn(\"location_key\", \n",
    "                       concat(lit(\"LOC_\"), col(\"area\"), lit(\"_\"), col(\"version_num\")))\n",
    "    \n",
    "    return df.select(\n",
    "        \"location_key\",\n",
    "        \"area\",\n",
    "        \"area_name\",\n",
    "        \"lat_clean\",\n",
    "        \"lon_clean\",\n",
    "        \"effective_date\",\n",
    "        \"end_date\",\n",
    "        \"is_current\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_to_stage_Scd2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
